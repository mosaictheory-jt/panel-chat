# Panel Chat - Cursor Rules

## Project Overview
Panel Chat is a full-stack app that lets users ask questions to AI agents representing real survey respondents. An LLM first breaks down the user's question into structured sub-questions with categorical answer options. The user reviews/edits the breakdown, then a LangGraph workflow fans out questions to persona-agents in parallel, collects structured responses, and streams results over WebSocket. Responses are automatically visualized with charts.

## Tech Stack

### Backend (Python 3.12+)
- **FastAPI** with async lifespan, CORS for localhost:5173
- **LangGraph** for multi-agent survey orchestration (fan-out pattern)
- **LangChain** chat models: Anthropic, OpenAI, Google Gemini
- **DuckDB** for persistence (respondents from CSV, surveys, responses)
- **Pydantic v2** models and settings
- **uv** for dependency management (use `uv add`, not pip)

### Frontend (TypeScript)
- **React 19** with Vite 7
- **Tailwind CSS v4** (via @tailwindcss/vite plugin, no tailwind.config)
- **shadcn/ui** components in `src/components/ui/` (Radix primitives + CVA)
- **Zustand** for state management
- **Recharts** for data visualization (bar and pie charts)
- **Lucide React** for icons

## Architecture

### Backend Structure
```
backend/
 main.py          # FastAPI app, lifespan, CORS, router mounting
 config.py        # Settings (duckdb_path, csv_path only - no API keys)
 db.py            # DuckDB connection, schema init
 models/          # Pydantic models
   survey.py      # SubQuestion, QuestionBreakdown, SurveyRequest, SurveyResponse, SurveySession, SurveySummary
   chat.py        # AgentMessage (WS event model)
   respondent.py  # Respondent, FilterOptions
   ws.py          # WSMessage
 routers/
   surveys.py     # CRUD + analyze + breakdown endpoints
   respondents.py # Filter options, count
   ws.py          # WebSocket for survey streaming
 services/
   llm.py         # get_llm() - provider auto-detection
   analyzer.py    # analyze_question() - LLM structured output for question breakdown
   history.py     # Survey CRUD (create_survey, save_response, list_surveys, get_survey, update_breakdown)
   panel.py       # Panel selection from respondents
 graph/
   state.py       # TypedDicts for SurveyState and SurveyAgentState
   nodes.py       # survey_respond node (structured answers)
   builder.py     # Graph construction with fan-out pattern (no rounds)
   prompts.py     # PERSONA_SYSTEM, SURVEY_USER, ANALYZER_SYSTEM
```

### Frontend Structure
```
frontend/src/
 App.tsx                       # Root layout + SettingsModal
 api/client.ts                 # HTTP API calls (createSurvey, analyzeSurvey, submitBreakdown, etc.)
 api/ws.ts                     # WebSocket connection (sends api_keys as first msg)
 store/surveyStore.ts          # Zustand store (phase machine, multi-key settings, survey state)
 hooks/useSurvey.ts            # Survey lifecycle hook (startSurvey, runSurvey, refreshHistory)
 types/index.ts                # Shared types, MODEL_OPTIONS, provider helpers
 components/
   SurveyView.tsx              # Phase-based rendering (idle/analyzing/reviewing/running/complete)
   BreakdownEditor.tsx         # Editable sub-questions and answer options
   ResultsView.tsx             # Chart grid for sub-questions
   SubQuestionChart.tsx        # Recharts bar/pie chart per sub-question
   ResponseCard.tsx            # Individual respondent answer card
   SettingsModal.tsx           # Multi-key, multi-model selection, analyzer model
   Sidebar.tsx                 # Survey history + filters
   ChatInput.tsx               # Question input
   FilterPanel.tsx             # Respondent filters
   Layout.tsx                  # App layout shell
 components/ui/                # shadcn/ui primitives (do not edit manually)
```

### Key Data Flow
1. User configures API keys per provider + selects models in SettingsModal (persisted to localStorage)
2. `createSurvey` POST sends question, models, panel_size, filters
3. Backend selects panel from respondents, stores survey with panel
4. `analyzeSurvey` POST uses LLM structured output to break question into sub-questions
5. User reviews/edits breakdown in BreakdownEditor, clicks "Run Survey"
6. Frontend opens WebSocket, sends `{"api_keys": {"anthropic": "...", ...}}` as first message
7. LangGraph fans out to survey_respond nodes (one per panelist per model)
8. Each persona answers sub-questions by choosing from categorical options
9. Responses stream back via WS as `survey_response` events
10. Charts auto-render with aggregated data (grouped by model if multiple selected)

### Phase State Machine
```
idle -> analyzing -> reviewing -> running -> complete
                  \-> error (back to idle)
```

## Conventions

### Python
- Type hints on all function signatures
- No server-side API keys - all keys come from the client
- `get_llm(model, api_key)` auto-detects provider from model name prefix
- DuckDB queries use parameterized statements
- Use `logging` module, never `print`
- Import sorting: stdlib, third-party, local

### TypeScript
- Functional components only, no classes
- Path alias `@/` maps to `src/`
- Store selectors: `useSurveyStore((s) => s.field)` for individual fields
- No semicolons in component files (project style)
- Destructure store values in components

### shadcn/ui
- Components live in `src/components/ui/` - add new ones via `npx shadcn@latest add <name>`
- Do not manually edit files in `components/ui/`
- App-level components compose UI primitives from this directory

### State Management
- API keys persist to localStorage (one per provider)
- Selected models persist to localStorage
- settingsOpen auto-opens if no API keys stored
- Survey state (phase, breakdown, responses) lives in Zustand, not persisted

## Running the App
```bash
# Backend
uv run uvicorn backend.main:app --reload

# Frontend
cd frontend && npm run dev
```

## Common Tasks

### Adding a new LLM provider
1. Add langchain integration to `pyproject.toml` via `uv add`
2. Update `backend/services/llm.py`: add prefix detection + model instantiation
3. Add models to `MODEL_OPTIONS` in `frontend/src/types/index.ts`
4. Add provider to `PROVIDER_NAMES` and `getProviderKey` in types
5. Add API key field in store and SettingsModal

### Adding a new shadcn component
```bash
cd frontend && npx shadcn@latest add <component-name>
```

### Database schema changes
- Edit `backend/db.py` `init_db()`
- Delete local `.duckdb` file to recreate (uses `CREATE TABLE IF NOT EXISTS`)
